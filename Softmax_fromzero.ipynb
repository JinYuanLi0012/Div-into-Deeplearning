{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d0ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from d2l import torch as d2l\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bced984",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37ca063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\n",
    "b = torch.zeros(num_outputs, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9edc8bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0413, 0.4877, 0.1412, 0.2704, 0.0594],\n",
       "         [0.7549, 0.0906, 0.0525, 0.0718, 0.0301]]),\n",
       " tensor([1.0000, 1.0000]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#softmax计算实现\n",
    "def softmax(X):\n",
    "    \n",
    "    X_exp = torch.exp(X)\n",
    "    \n",
    "    partition = X_exp.sum(dim=1, keepdim=True)\n",
    "    \n",
    "    return X_exp / partition  # 这里应用了广播机制\n",
    "\n",
    "#简单测试\n",
    "X = torch.normal(0,1,(2,5))\n",
    "\n",
    "X_prob = softmax(X)\n",
    "\n",
    "X_prob,X_prob.sum(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38c46a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax回归模型\n",
    "def net(X):\n",
    "    return softmax(torch.matmul(X.reshape(-1,W.shape[0]),W)+b)\n",
    "\n",
    "# def net(X):\n",
    "#     return softmax(torch.mm(X.view((-1, num_inputs)), W) + b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28ab290e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.5000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n",
    "y = torch.tensor([0, 2])\n",
    "y_hat[range(len(y_hat)),y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b814e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 0.6931])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##交叉熵实现\n",
    "def cross_entropy(y_hat,y):\n",
    "    return -torch.log(y_hat[range(len(y_hat)),y])\n",
    "\n",
    "cross_entropy(y_hat,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54482dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##预测正确率的计算\n",
    "def accuracy(y_hat,y):\n",
    "    \n",
    "    if len(y_hat.shape)>1 and y_hat.shape[1] >1:\n",
    "        \n",
    "        y_hat = y_hat.argmax(axis =1) #y_hat矩阵中每一行里最大值的下标被找出来，得到一个一维数组，再赋值给yhat\n",
    "                                      #这里每行的最大值下标，代表的就正是每行最后的分类结果，即最终预测为第几类\n",
    "            \n",
    "    cmp = y_hat.type(y.dtype) == y    #两个矩阵里的每个元素相比较，对应位置相同的元素，则为TRUE，反之Flase，最后存在cmp里\n",
    "     \n",
    "    return float(cmp.type(y.dtype).sum())  #将cmp这个列向量里的所有1求和，得到的总和即为预测正确的个数\n",
    "\n",
    "accuracy(y_hat,y)/len(y)              #预测正确的总个数，除以总共样本数，得到准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0e9f040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0825\n"
     ]
    }
   ],
   "source": [
    "# 评价net在数据集上的准确率\n",
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用。该函数将被逐步改进：它的完整实现将在“图像增广”一节中描述\n",
    "def evaluate_accuracy(data_iter, net):\n",
    "    \n",
    "    acc_sum, n = 0.0, 0\n",
    "    \n",
    "    for X, y in data_iter:\n",
    "        \n",
    "        prd_X = net(X)\n",
    "        \n",
    "        prd_X = prd_X.argmax(axis=1)\n",
    "        \n",
    "        cmp = prd_X.type(y.dtype) == y\n",
    "        \n",
    "        acc_sum += float(cmp.type(y.dtype).sum())\n",
    "        \n",
    "        n += y.shape[0]\n",
    "    \n",
    "    return acc_sum / n\n",
    "\n",
    "print(evaluate_accuracy(test_iter, net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4275af2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.7848, train acc 0.748, test acc 0.789\n",
      "epoch 2, loss 0.5694, train acc 0.814, test acc 0.802\n",
      "epoch 3, loss 0.5252, train acc 0.826, test acc 0.820\n",
      "epoch 4, loss 0.5016, train acc 0.831, test acc 0.826\n",
      "epoch 5, loss 0.4862, train acc 0.836, test acc 0.827\n"
     ]
    }
   ],
   "source": [
    "num_epochs, lr = 5, 0.1\n",
    "\n",
    "# 本函数已保存在d2lzh包中方便以后使用\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,\n",
    "              params=None, lr=None, optimizer=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for X, y in train_iter:\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).sum()\n",
    "\n",
    "            # 梯度清零\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "\n",
    "            l.backward()\n",
    "            if optimizer is None:\n",
    "                d2l.sgd(params, lr, batch_size)\n",
    "            else:\n",
    "                optimizer.step()  # “softmax回归的简洁实现”一节将用到\n",
    "\n",
    "\n",
    "            train_l_sum += l\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum()\n",
    "            n += y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
    "\n",
    "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W, b], lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3ceea3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3048\\2805410348.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_fashion_mnist_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtitles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrue\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mshow_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'show_images' is not defined"
     ]
    }
   ],
   "source": [
    "def get_fashion_mnist_labels(labels):  # @save\n",
    "    \"\"\"返回Fashion-MNIST数据集的文本标签。\"\"\"\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]\n",
    "X, y = iter(test_iter).next()\n",
    "true_labels = get_fashion_mnist_labels(y.numpy())\n",
    "pred_labels = get_fashion_mnist_labels(net(X).argmax(dim=1).numpy())\n",
    "titles = [true + '\\n' + pred for true, pred in zip(true_labels, pred_labels)]\n",
    "show_images(X[0:9], titles[0:9])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf21",
   "language": "python",
   "name": "tf21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
